---
title: "yes_english_data_joining"
author: "Mallory Dobias"
date: "`r format(Sys.time(), '%B %d, %Y')`"
output:
  html_document:
    toc: yes
    toc_depth: 5
    toc_float:
      collapsed: no
      smooth_scroll: no
  pdf_document:
    toc: yes
    toc_depth: '5'
  word_document:
    toc: yes
    toc_depth: '5'
geometry: margin=0.50in
---

```{r setup, include=FALSE}

## Setting up R

knitr::opts_chunk$set(echo = TRUE)

if(!require(pointblank)){install.packages('pointblank')}
library(pointblank) # installing and calling pointblank package early in Markdown

validate_rmd(summary = TRUE, log_to_file = FALSE) # allowing validation from pointblank package within Markdown

```

```{r, include=FALSE}

if(!require(here)){install.packages('here')}
library(here)

if(!require(dplyr)){install.packages('dplyr')}
library(dplyr)

if(!require(stringr)){install.packages('stringr')}
library(stringr)

if(!require(tidyr)){install.packages('tidyr')}
library(tidyr)

if(!require(readr)){install.packages('readr')}
library(readr)

```

# Data Reading

```{r reading in data}

## Reading in all cleaned english survey data

library(here) # places working directory at root of project folder

d02_data <- readRDS(here("data", "clean", "yes_data_d02_english_clean.Rds")) # directing to data from project folder root

d09_data <- readRDS(here("data", "clean", "yes_data_d09_english_clean.Rds")) # directing to data from project folder root

# head(d02_data)
# head(d02_data)

```

# Binding Data

```{r binding data}

## Binding data from all sources

data <- bind_rows(d02_data, d09_data)

```

Checking final data has expected number of rows

```{r checking n rows, validate = TRUE}

## Checking if the row count of data equals the sum of row counts of component dfs

validation_result <- 
  data %>%
  expect_row_count_match(nrow(d02_data) + nrow(d09_data))

## Printing the validation result - runs if passes

validation_result

```

Checking final data has expected number of columns

```{r checking n cols setup}

## Counting the number of expected shared and unique columns

# Creating dfs of col names from each component df

d02_cols <- data.frame(column_name = names(d02_data))

d09_cols <- data.frame(column_name = names(d09_data))

# Pulling n shared cols between dfs

n_shared_cols <- d02_cols %>%
  inner_join(d09_cols) %>%
  nrow()

# Pulling n cols unique to each df and total unique cols across dfs

n_unique_cols_d02 <- d02_cols %>%
  anti_join(d09_cols) %>%
  nrow()

n_unique_cols_d09 <- d09_cols %>%
  anti_join(d02_cols) %>%
  nrow()

n_unique_cols <- n_unique_cols_d02 + n_unique_cols_d09

```

```{r calc expected n cols}

# Calculating expected n cols (shared plus unique cols)

n_expected_cols <- n_shared_cols + n_unique_cols

```

```{r checking n cols, validate = TRUE}

## Checking if the cols count of data equals the sum of cols counts of component dfs

validation_result <- 
  data %>%
  expect_col_count_match(n_expected_cols)

## Printing the validation result - runs if passes

validation_result

```

# Saving Data

```{r saving cleaned bound data}

# Define the folder and file path

folder_path <- here("data", "clean")  # Path to my desired folder
file_name <- "yes_data_english_clean.Rds"
full_path <- file.path(folder_path, file_name)

# Save the dataframe to the .csv file

saveRDS(data, full_path)

```